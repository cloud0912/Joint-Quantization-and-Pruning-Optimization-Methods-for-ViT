# 自注意力头激活量化与剪枝联合优化算法

## 项目简介

本项目提出了一种新颖的视觉Transformer模型压缩方法，通过以下创新技术实现模型轻量化：

1. **自注意力头激活量化策略**：
   - 考虑自注意力头中激活的异质分布特征
   - 动态捕获量化参数以最小化多头自注意力层中的近似误差
   - 采用运行时估计降低量化参数存储成本
   - 实现8比特量化同时保持模型性能

2. **输入维度剪枝算法**：
   - 评估线性层输入序列各维度的重要性
   - 使用L1正则稀疏化重要性评分
   - 实现更高剪枝比例，减少准确度损失
   - 显著提升网络计算效率

实验结果表明，在ImageNet-100数据集上，本方法能灵活节约内存，同时保持与基准模型相当甚至更好的性能。

## 主要特性

- 🚀 **高效量化**：针对自注意力头的异质分布特性优化8比特量化
- 💾 **低存储开销**：运行时估计减少量化参数存储需求
- ✂️ **智能剪枝**：基于输入维度重要性的剪枝策略
- ⚖️ **联合优化**：量化与剪枝协同工作，最大化压缩效果
- 📊 **性能保持**：在ImageNet-100上达到基准模型水平


## 贡献

欢迎贡献！请提交pull request或创建issue讨论新特性。

## 许可证

本项目采用 [MIT License](LICENSE)。
