{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47554b89-8c82-42d5-95ac-f7045ad9641a",
   "metadata": {},
   "source": [
    "# 这里没有剪枝和量化，最干净的模型，以后剪枝的时候记得加上L1，在train里面"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bafc91b-146b-4ebe-b966-cba2c7aee3ec",
   "metadata": {},
   "source": [
    "# 调用库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83167563-06b2-4534-bf10-ec997df2db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "\n",
    "Train imagenet100 with PyTorch and Vision Transformers!\n",
    "\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# from models.pruning_quantify_vit import ViT as pruning_quantify_vit\n",
    "\n",
    "from models.quantify_ALL import ViT as quantify_ALL\n",
    "from models.quantify_CLS_vit import ViT as quantify_CLS_vit\n",
    "from models.quantify_FNN_vit import ViT as quantify_FNN_vit\n",
    "from models.quantify_MHA_vit import ViT as quantify_MHA_vit\n",
    "\n",
    "from models.quantify_head_vit import ViT as quantify_head_vit\n",
    "from models.quantify_layer_vit import ViT as quantify_layer_vit\n",
    "\n",
    "from models.quantify_weight_activation import ViT as quantify_weight_activation\n",
    "from models.quantify_weight_only import ViT as quantify_weight_only\n",
    "\n",
    "from models.pruning_quantify_vit import ViT as pruning_quantify_vit\n",
    "\n",
    "from models.vit import ViT as vit\n",
    "from models.pruning_quantify_vit import channel_selection\n",
    "from utils import progress_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b75b6d9-963c-4360-972e-2d409b5cab2f",
   "metadata": {},
   "source": [
    "# 设置输入参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406c29c-63b4-42c6-a0b8-03f3640fb032",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# parsers\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet100 Training')\n",
    "parser.add_argument('--lr', default=1e-4, type=float, help='learning rate') # resnets.. 1e-3, Vit..1e-4?\n",
    "parser.add_argument('--opt', default=\"adam\")\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "parser.add_argument('--net', default='vit')\n",
    "parser.add_argument('--bs', default='64')\n",
    "parser.add_argument('--n_epochs', type=int, default='100')\n",
    "parser.add_argument('--patch', default='16', type=int)\n",
    "parser.add_argument('--cos', action='store_true', help='Train with cosine annealing scheduling')\n",
    "parser.add_argument(\"--bit\", type=int, help=\"bit number for weight each parameter\", choices=[8,4,2], default=None)\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.cos:\n",
    "    from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "bs = int(args.bs)\n",
    "k = args.bit\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5b7918-163c-4068-a9b1-976b11a10956",
   "metadata": {},
   "source": [
    "# 设置数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19caa24-6255-499f-8259-120ed473db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data\n",
    "# print('==> Preparing data..')\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.Resize(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.Resize(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='/home/lxc/ABCPruner/data', train=True, download=True, transform=transform_train)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=8)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='/home/lxc/ABCPruner/data', train=False, download=True, transform=transform_test)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3aee441-77fc-4838-aa31-02687576c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# 设置数据集路径\n",
    "dataset_path = '../autodl-tmp/data/imagenet100'\n",
    "\n",
    "# 图像预处理 - 为训练集和验证集定义不同的转换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 验证集不使用数据增强，只进行必要的预处理\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 加载数据集并应用预处理\n",
    "train_dataset = datasets.ImageFolder(root=dataset_path, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=dataset_path, transform=val_transform)\n",
    "\n",
    "# 划分数据集为训练集和验证集\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(val_dataset) - train_size\n",
    "train_dataset, _ = random_split(train_dataset, [train_size, len(train_dataset) - train_size])\n",
    "_, val_dataset = random_split(val_dataset, [train_size, len(val_dataset) - train_size])\n",
    "\n",
    "# 创建 DataLoader\n",
    "trainloader = DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=8,pin_memory = True)\n",
    "testloader = DataLoader(val_dataset, batch_size=bs, shuffle=False, num_workers=8,pin_memory= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fdeb6-0482-467d-9ae8-beab10b30ee5",
   "metadata": {},
   "source": [
    "# 设置模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b128696a-5191-4b38-a29c-6a92eefb4ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "print('==> Building model..')\n",
    "\n",
    "shared_params = {\n",
    "    \"image_size\": 224,\n",
    "    \"patch_size\": args.patch,\n",
    "    \"num_classes\": 100,\n",
    "    \"dim\": 384,\n",
    "    \"depth\": 12,\n",
    "    \"heads\": 6,\n",
    "    \"mlp_dim\": 1536,\n",
    "    \"dropout\": 0.01,\n",
    "    \"emb_dropout\": 0.01\n",
    "}\n",
    "\n",
    "L1 = False\n",
    "msa = True\n",
    "\n",
    "if args.net=='quantify_ALL':\n",
    "    net = quantify_ALL(**shared_params)    \n",
    "elif args.net=='quantify_CLS_vit':\n",
    "    net = quantify_CLS_vit(**shared_params)    \n",
    "elif args.net=='quantify_FNN_vit':\n",
    "    net = quantify_FNN_vit(**shared_params)    \n",
    "elif args.net=='quantify_MHA_vit':\n",
    "    net = quantify_MHA_vit(**shared_params)  \n",
    "    \n",
    "elif args.net=='quantify_head_vit':\n",
    "    net = quantify_head_vit(**shared_params)\n",
    "elif args.net=='quantify_layer_vit':\n",
    "    net = quantify_layer_vit(**shared_params)  \n",
    "    \n",
    "elif args.net=='quantify_weight_activation':\n",
    "    net = quantify_weight_activation(**shared_params)    \n",
    "elif args.net=='quantify_weight_only':\n",
    "    net = quantify_weight_only(**shared_params) \n",
    "\n",
    "elif args.net=='pruning_quantify_vit':\n",
    "    net = pruning_quantify_vit(**shared_params)    \n",
    "    L1 = True\n",
    "elif args.net==\"vit\":\n",
    "    # ViT for cifar10\n",
    "    net = ViT(**shared_params)\n",
    "    msa = False\n",
    "    \n",
    "cudnn.benchmark = True\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8b188-fb91-4f95-ac51-0acf37ebdcee",
   "metadata": {},
   "source": [
    "# 调入预训练参数或checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2932956-b6f7-4f85-8194-7a1f3466c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(r'../pretrain/S_16_model_parameters.pth'))\n",
    "\n",
    "if args.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/{}-ckpt.t7'.format(args.net))\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e5668-f711-45ce-87dc-751a4f57e6e9",
   "metadata": {},
   "source": [
    "# 设置学习率，优化器，损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bb6db-29eb-4105-b741-455974b48436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss is CE\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# reduce LR on Plateau\n",
    "if args.opt == \"adam\":\n",
    "    optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
    "elif args.opt == \"sgd\":\n",
    "    optimizer = optim.SGD(net.parameters(), lr=args.lr)    \n",
    "elif args.opt == \"adamw\":\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=args.lr, weight_decay=5e-4)\n",
    "\n",
    "if not args.cos:\n",
    "    from torch.optim import lr_scheduler\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True, min_lr=1e-3*1e-5, factor=0.1)\n",
    "else:\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs-1)\n",
    "    scheduler = GradualWarmupScheduler(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n",
    "    \n",
    "def sparse_selection():\n",
    "    s = 1e-4\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, channel_selection):\n",
    "            m.indexes.grad.data.add_(s*torch.sign(m.indexes.data))  # L1            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40ba2da-548c-4606-9931-c26fcd32e8cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 训练及验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1978d-6452-4554-b1c9-9a9a61a7d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        if L1:\n",
    "            sparse_selection()\n",
    "        optimizer.step()\n",
    "        if ema:\n",
    "            net.apply_ema(k)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    return train_loss/(batch_idx+1)\n",
    "\n",
    "##### Validation\n",
    "import time\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    # Update scheduler\n",
    "    if not args.cos:\n",
    "        scheduler.step(test_loss)\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/'+args.net+'-{}-ckpt.t7'.format(args.patch))\n",
    "        best_acc = acc\n",
    "    \n",
    "    os.makedirs(\"log\", exist_ok=True)\n",
    "    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, val loss: {test_loss:.5f}, acc: {(acc):.5f}'\n",
    "    print(content)\n",
    "    with open(f'log/log_{args.net}_patch{args.patch}.txt', 'a') as appender:\n",
    "        appender.write(content + \"\\n\")\n",
    "    return test_loss, acc\n",
    "\n",
    "list_loss = []\n",
    "list_acc = []\n",
    "for epoch in range(start_epoch, args.n_epochs):\n",
    "    trainloss = train(epoch)\n",
    "    val_loss, acc = test(epoch)\n",
    "    \n",
    "    if args.cos:\n",
    "        scheduler.step(epoch-1)\n",
    "    \n",
    "    list_loss.append(val_loss)\n",
    "    list_acc.append(acc)\n",
    "    \n",
    "    # write as csv for analysis\n",
    "    with open(f'log/log_{args.net}_patch{args.patch}.csv', 'w') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        writer.writerow(list_loss) \n",
    "        writer.writerow(list_acc) \n",
    "    # print(list_loss)\n",
    "    \n",
    "    with open(f'log/log_{args.net}_patch{args.patch}.csv', 'w') as f:\n",
    "        writer = csv.writer(f, lineterminator='\\n')\n",
    "        # 写入标题行\n",
    "        writer.writerow(['Loss', 'Accuracy'])\n",
    "        # 使用 zip 同时遍历 list_loss 和 list_acc\n",
    "        for loss, acc in zip(list_loss, list_acc):\n",
    "            # 将每对 loss 和 acc 作为一行中的两个不同列写入\n",
    "            writer.writerow([loss, acc])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f92d1-f016-4887-b748-6c61de8dd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsize = (1, 3, 224, 224)\n",
    "inputs = torch.randn(dsize).to(device)\n",
    "memory_size, params, flops = count_MemorySize_Params_FLOPs(net , inputs)\n",
    "\n",
    "print('Net:',args.net)\n",
    "print('MemorySize:',memory_size)\n",
    "print('Paras:',params)\n",
    "print('FLOPs:',flops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
